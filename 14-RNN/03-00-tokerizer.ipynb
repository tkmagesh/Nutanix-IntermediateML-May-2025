{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index: {'<OOV>': 1, 'i': 2, 'learning': 3, 'love': 4, 'deep': 5, 'get': 6, 'to': 7, 'learn': 8, 'a': 9, 'lot': 10, 'machine': 11, 'is': 12, 'amazing': 13}\n",
      "Sequences: [[2, 4, 5, 3, 2, 6, 7, 8, 9, 1], [1, 3, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentences = [\"I love deep learning. I get to learn a lot\", \"Machine learning is amazing\"]\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Convert sentences to sequences (integer encoding)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Print results\n",
    "print(\"Word Index:\", tokenizer.word_index)\n",
    "print(\"Sequences:\", sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nutanix_int_ml_kernel",
   "language": "python",
   "name": "nutanix_int_ml_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
