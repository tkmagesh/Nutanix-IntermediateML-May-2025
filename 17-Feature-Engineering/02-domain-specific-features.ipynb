{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Are Domain-Specific Features?\n",
    "Domain-specific features are variables or attributes engineered based on expert knowledge or insights about the problem’s domain. Unlike generic features (e.g., raw data like height, weight, or pixel values), these are tailored to capture patterns, relationships, or nuances that are particularly relevant to the task at hand. The idea is to transform raw data into something more meaningful for a machine learning model, often improving its ability to generalize and make accurate predictions.\n",
    "\n",
    "For example:\n",
    "- In a medical dataset, raw data might include \"blood pressure\" and \"heart rate.\" A domain-specific feature could be \"cardiovascular risk score,\" derived from combining these using a formula informed by medical expertise.\n",
    "- In a text classification task, instead of just word counts, you might add a feature like \"sentiment score\" based on linguistic rules.\n",
    "\n",
    "The impact? By embedding domain knowledge, the model gets a head start—it’s not just blindly searching for patterns but working with data that’s already structured to highlight what matters.\n",
    "\n",
    "### How It Impacts Model Accuracy\n",
    "1. **Before (Without Domain-Specific Features):**\n",
    "   - The model relies solely on raw or basic features.\n",
    "   - It might miss subtle but critical patterns unless the dataset is massive and the model is complex enough to learn them implicitly.\n",
    "   - Accuracy can suffer due to noise, irrelevant features, or insufficient signal in the raw data.\n",
    "\n",
    "2. **After (With Domain-Specific Features):**\n",
    "   - The model leverages features that emphasize relevant relationships or reduce noise.\n",
    "   - It often learns faster and performs better, especially with smaller datasets or simpler models.\n",
    "   - Accuracy improves because the input data is more aligned with the underlying problem structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Using raw features only\n",
      "RMSE with raw features: 52959.51\n",
      "\n",
      "After: Adding domain-specific features\n",
      "RMSE with enhanced features: 52918.23\n",
      "\n",
      "Feature Importances:\n",
      "square_footage: 0.905\n",
      "bedrooms: 0.005\n",
      "bathrooms: 0.005\n",
      "distance_to_city: 0.015\n",
      "year_built: 0.010\n",
      "price_per_sqft: 0.000\n",
      "bedroom_to_bathroom_ratio: 0.005\n",
      "house_age: 0.009\n",
      "space_per_room: 0.030\n",
      "proximity_value: 0.016\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate a synthetic housing dataset\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'square_footage': np.random.uniform(800, 4000, n_samples),  # House size in square feet\n",
    "    'bedrooms': np.random.randint(1, 6, n_samples),             # Number of bedrooms\n",
    "    'bathrooms': np.random.randint(1, 4, n_samples),           # Number of bathrooms\n",
    "    'distance_to_city': np.random.uniform(1, 20, n_samples),   # Distance to city center (miles)\n",
    "    'year_built': np.random.randint(1950, 2020, n_samples),    # Year the house was built\n",
    "}\n",
    "\n",
    "# Create a synthetic target variable (house price)\n",
    "# Price depends on square footage, bedrooms, bathrooms, distance to city, and age\n",
    "df = pd.DataFrame(data)\n",
    "df['price'] = (\n",
    "    200 * df['square_footage'] +\n",
    "    20000 * df['bedrooms'] +\n",
    "    30000 * df['bathrooms'] -\n",
    "    5000 * df['distance_to_city'] -\n",
    "    1000 * (2023 - df['year_built']) +  # Older houses are cheaper\n",
    "    np.random.normal(0, 50000, n_samples)  # Add some noise\n",
    ")\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df.drop('price', axis=1).values\n",
    "y = df['price'].values\n",
    "\n",
    "# Before: Using only raw features\n",
    "print(\"Before: Using raw features only\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate model with raw features\n",
    "rf_before = RandomForestRegressor(random_state=42)\n",
    "rf_before.fit(X_train, y_train)\n",
    "y_pred_before = rf_before.predict(X_test)\n",
    "mse_before = mean_squared_error(y_test, y_pred_before)\n",
    "rmse_before = np.sqrt(mse_before)\n",
    "print(f\"RMSE with raw features: {rmse_before:.2f}\\n\")\n",
    "\n",
    "# After: Adding domain-specific features\n",
    "print(\"After: Adding domain-specific features\")\n",
    "\n",
    "# Create new features based on domain knowledge\n",
    "def create_domain_features(X):\n",
    "    df = pd.DataFrame(X, columns=['square_footage', 'bedrooms', 'bathrooms', 'distance_to_city', 'year_built'])\n",
    "    \n",
    "    # Domain-specific features\n",
    "    df['price_per_sqft'] = 200  # Simulate a rough price per square foot (based on how price was generated)\n",
    "    df['bedroom_to_bathroom_ratio'] = df['bedrooms'] / df['bathrooms']\n",
    "    df['house_age'] = 2023 - df['year_built']  # Current year - year built\n",
    "    df['space_per_room'] = df['square_footage'] / (df['bedrooms'] + df['bathrooms'])\n",
    "    df['proximity_value'] = 1 / (df['distance_to_city'] + 1)  # Inverse distance (closer = more valuable)\n",
    "    \n",
    "    return df.values\n",
    "\n",
    "# Create new feature matrix\n",
    "X_enhanced = create_domain_features(X)\n",
    "X_train_enh, X_test_enh, y_train, y_test = train_test_split(X_enhanced, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate model with enhanced features\n",
    "rf_after = RandomForestRegressor(random_state=42)\n",
    "rf_after.fit(X_train_enh, y_train)\n",
    "y_pred_after = rf_after.predict(X_test_enh)\n",
    "mse_after = mean_squared_error(y_test, y_pred_after)\n",
    "rmse_after = np.sqrt(mse_after)\n",
    "print(f\"RMSE with enhanced features: {rmse_after:.2f}\")\n",
    "\n",
    "# Print feature importance for the enhanced model\n",
    "feature_names = ['square_footage', 'bedrooms', 'bathrooms', 'distance_to_city', 'year_built',\n",
    "                 'price_per_sqft', 'bedroom_to_bathroom_ratio', 'house_age', 'space_per_room', 'proximity_value']\n",
    "print(\"\\nFeature Importances:\")\n",
    "for name, importance in zip(feature_names, rf_after.feature_importances_):\n",
    "    print(f\"{name}: {importance:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nutanix_int_ml_kernel",
   "language": "python",
   "name": "nutanix_int_ml_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
