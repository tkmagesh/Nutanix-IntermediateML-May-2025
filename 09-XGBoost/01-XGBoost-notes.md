### **XGBoost**  

XGBoost (**eXtreme Gradient Boosting**) is a powerful and efficient machine learning algorithm based on **gradient boosting**. It is widely used for structured/tabular data and consistently achieves top performance in competitions like Kaggle.  

---

### **How Does XGBoost Work?**  
1. **Ensemble Learning:** XGBoost builds multiple decision trees sequentially. Each tree learns from the mistakes of the previous ones.  
2. **Gradient Boosting:** It minimizes errors using gradient descent, adjusting the model step by step.  
3. **Handling Missing Values:** It can automatically handle missing data, making it robust for real-world datasets.  

---

### **Why Use XGBoost?**  
- **High accuracy** – Often outperforms other models  
- **Fast training** – Optimized for speed and efficiency  
- **Handles missing data** – No need for manual imputation  
- **Prevents overfitting** – Built-in regularization  
- **Works well with tabular data** – Ideal for structured datasets  



### **When to Use XGBoost?**  
- Large datasets with structured/tabular data  
- Classification or regression problems  
- When you need a fast and accurate model  


